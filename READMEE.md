# 模型介绍：

之所以会出现两个模型，是因为两个模型的reader不一样。
刚开始是用的Lip-TSM-1来进行训练的成绩是0.76,后面修改了reader,然后继续利用了Lip-TSM-1的模型作为了预训练模型来训练Lip-TSM-2，成绩是0.82。

### 模型方法

- Lip-TSM-1:序列长度固定为了12帧，后面的舍弃了
- Lip-TSM-2:序列长度固定为了24帧，利用了一些插补的方式
- 两个模型的图片大小都是将图片缩放到120x120，并随机Crop出100x100的图片，送入图片序列
- 两个模型皆是采用的resnet50作为backbone

### 模型结果

后面单独训练了Lip-TSM-2，成绩是0.80左右
猜测是Lip-TSM-1的模型用了不同的reader,进而提高了Lip-TSM-2的泛化能力

| 模型      | ACC  | 备注                |
| --------- | ---- | ------------------- |
| Lip-TSM-1 | 0.76 | 单模                |
| Lip-TSM-2 | 0.80 | 单模                |
| Lip-TSM-2 | 0.82 | Lip-TSM-1->Lip-TSM2 |

### 操作步骤

#### 配置环境

请按照Lip-TSM-1的README.md，进行环境配置

#### 复现B榜结果

请直接按照Lip-TSM-2的README执行预测步骤，并且将权重设为checkpoints_models_best082

#### 模型融合

该融合利用了torch的两个模型结果和一个paddle的最优结果，请修改TSMS/fusion.py中的三个结果路径，生成最终结果

```
python fusion.py
```

这个融合策略是我们截止日期前最后一个小时做的，只是简单的比较了三个文件的每个预测结果的score分数，虽然有提升，但不是最优的融合策略; 

我们最初的想法是每个预测结果的所有类的概率都输出出来，然后所有模型的所有预测结果的所有类的score相加，再利用argmax看哪个类的score最大; 还有利用交叉验证策略，最终时间关系没有利用这些方式

#### 重新训练

1、按照Lip-TSM-1的README.md中的训练步骤进行操作

2、按照Lip-TSM-2的README.md中的训练步骤进行操作，利用Lip-TSM-1的最优模型作为预训练